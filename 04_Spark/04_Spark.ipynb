{"nbformat":4,"nbformat_minor":0,"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"04_Spark.ipynb","provenance":[],"collapsed_sections":["fGsih3q0NrKI","c6IFRE0kNrKJ"]}},"cells":[{"cell_type":"markdown","metadata":{"id":"X_aR9xT5NrKC"},"source":["# 3. Spark\n","\n","Spark Programming Guide: <https://spark.apache.org/docs/latest/> (use Python API recommended)\n","Spark API: <https://spark.apache.org/docs/latest/api/python/index.html>\n","\n","\n","# 3.1 Example Walkthrough\n","3.1 Follow the Spark Examples below! After completion see Exercise 3.2 and 3.3!\n","\n","\n","### Initialize PySpark\n","\n","First, we use the findspark package to initialize PySpark."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5Zw7iFCN0ED","executionInfo":{"status":"ok","timestamp":1615716675783,"user_tz":-60,"elapsed":40046,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"0555b7aa-9b20-4908-9fc3-a1423d8bc189"},"source":["!pip install pyspark"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n","\u001b[K     |████████████████████████████████| 212.3MB 72kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 21.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=ba98f4adcbc9a82253a4c5bbc6acf2cfce1d519a8ac9bfa9dc34e7e33e9d6b77\n","  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"pirTc4KfNrKG"},"source":["import os, sys"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PQrr41GwNrKI","executionInfo":{"status":"ok","timestamp":1615716742055,"user_tz":-60,"elapsed":7473,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"a187f48e-d995-4db0-d397-7d5305823f4e"},"source":["# Initialize PySpark\n","APP_NAME = \"PySpark Lecture\"\n","SPARK_MASTER=\"local[1]\"\n","import pyspark\n","import pyspark.sql\n","from pyspark.sql import Row\n","conf=pyspark.SparkConf()\n","conf=pyspark.SparkConf().setAppName(APP_NAME).set(\"spark.local.dir\", os.path.join(os.getcwd(), \"tmp\"))\n","sc = pyspark.SparkContext(master=SPARK_MASTER, conf=conf)\n","spark = pyspark.sql.SparkSession(sc).builder.appName(APP_NAME).getOrCreate()\n","\n","print(\"PySpark initiated...\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["PySpark initiated...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"fGsih3q0NrKI"},"source":["### Hello, World!\n","\n","Loading data, mapping it and collecting the records into RAM..."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XSNJTxUOU7xG","executionInfo":{"status":"ok","timestamp":1615718551576,"user_tz":-60,"elapsed":1485,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"2b279c5a-bac3-4043-fede-99ed74fcda3c"},"source":["!wget https://raw.githubusercontent.com/scalable-infrastructure/exercise-students-2021/master/data/example.csv"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-14 10:42:30--  https://raw.githubusercontent.com/scalable-infrastructure/exercise-students-2021/master/data/example.csv\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 189 [text/plain]\n","Saving to: ‘example.csv.1’\n","\n","example.csv.1       100%[===================>]     189  --.-KB/s    in 0s      \n","\n","2021-03-14 10:42:30 (15.4 MB/s) - ‘example.csv.1’ saved [189/189]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pt0wm3GQNrKI","executionInfo":{"status":"ok","timestamp":1615716794158,"user_tz":-60,"elapsed":3280,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"83d24461-1f0b-44db-bd61-c0a3e116cd04"},"source":["# Load the text file using the SparkContext\n","csv_lines = sc.textFile(\"example.csv\")\n","\n","# Map the data to split the lines into a list\n","data = csv_lines.map(lambda line: line.split(\",\"))\n","\n","# Collect the dataset into local RAM\n","data.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['Russell Jurney', 'Relato', 'CEO'],\n"," ['Florian Liebert', 'Mesosphere', 'CEO'],\n"," ['Don Brown', 'Rocana', 'CIO'],\n"," ['Steve Jobs', 'Apple', 'CEO'],\n"," ['Donald Trump', 'The Trump Organization', 'CEO'],\n"," ['Russell Jurney', 'Data Syndrome', 'Principal Consultant']]"]},"metadata":{"tags":[]},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"c6IFRE0kNrKJ"},"source":["### Creating Objects from CSV\n","\n","Using a function with a map operation to create objects (dicts) as records..."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wFzFYn0MNrKJ","executionInfo":{"status":"ok","timestamp":1615716800399,"user_tz":-60,"elapsed":1203,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"d3e023c8-6807-4013-a633-3f52ee418675"},"source":["# Turn the CSV lines into objects\n","def csv_to_record(line):\n","    parts = line.split(\",\")\n","    record = {\n","      \"name\": parts[0],\n","      \"company\": parts[1],\n","      \"title\": parts[2]\n","    }\n","    return record\n","\n","# Apply the function to every record\n","records = csv_lines.map(csv_to_record)\n","\n","# Inspect the first item in the dataset\n","records.first()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'company': 'Relato', 'name': 'Russell Jurney', 'title': 'CEO'}"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"ZjMBodwrNrKJ"},"source":["### GroupBy\n","\n","Using the groupBy operator to count the number of jobs per person..."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NfOqDcz6NrKJ","executionInfo":{"status":"ok","timestamp":1615716805677,"user_tz":-60,"elapsed":1947,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"51336ca5-94a9-4b19-8a03-7a3aa8a30369"},"source":["# Group the records by the name of the person\n","grouped_records = records.groupBy(lambda x: x[\"name\"])\n","\n","# Show the first group\n","grouped_records.first()\n","\n","# Count the groups\n","job_counts = grouped_records.map(\n","  lambda x: {\n","    \"name\": x[0],\n","    \"job_count\": len(x[1])\n","  }\n",")\n","\n","job_counts.first()\n","\n","job_counts.collect()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'job_count': 2, 'name': 'Russell Jurney'},\n"," {'job_count': 1, 'name': 'Florian Liebert'},\n"," {'job_count': 1, 'name': 'Don Brown'},\n"," {'job_count': 1, 'name': 'Steve Jobs'},\n"," {'job_count': 1, 'name': 'Donald Trump'}]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"unQf6WJhNrKK"},"source":["### Map vs FlatMap\n","\n","Understanding the difference between the map and flatmap operators..."]},{"cell_type":"code","metadata":{"id":"t0W5jyqtNrKK"},"source":["# Compute a relation of words by line\n","words_by_line = csv_lines\\\n","  .map(lambda line: line.split(\",\"))\n","\n","print(words_by_line.collect())\n","\n","# Compute a relation of words\n","flattened_words = csv_lines\\\n","  .map(lambda line: line.split(\",\"))\\\n","  .flatMap(lambda x: x)\n","\n","flattened_words.collect()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SnQTDbiWNrKK"},"source":["---\n","## Further Exercises\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HrTk8P9iORnI","executionInfo":{"status":"ok","timestamp":1615718101014,"user_tz":-60,"elapsed":51092,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"53e1cbc2-ad79-4bb9-c0e4-c7c8393b8e2c"},"source":["!wget https://raw.githubusercontent.com/scalable-infrastructure/exercise-students-2021/master/data/nasa/NASA_access_log_Jul95.gz\n","!gzip -d NASA_access_log_Jul95.gz"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2021-03-14 10:34:10--  https://raw.githubusercontent.com/scalable-infrastructure/exercise-students-2021/master/data/nasa/NASA_access_log_Jul95.gz\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 20676677 (20M) [application/octet-stream]\n","Saving to: ‘NASA_access_log_Jul95.gz’\n","\n","NASA_access_log_Jul 100%[===================>]  19.72M  43.8MB/s    in 0.5s    \n","\n","2021-03-14 10:34:10 (43.8 MB/s) - ‘NASA_access_log_Jul95.gz’ saved [20676677/20676677]\n","\n","gzip: NASA_access_log_Jul95 already exists; do you wish to overwrite (y or n)? y\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YZO5zgmrNrKK"},"source":["3.2 Implement a wordcount using Spark. How many words are in the file `example.csv`?\n","\n","3.3 Using the NASA Log file, implement a Spark version of the HTTP Response Code Analysis. How many log enteries per HTTP Response Code exist? "]},{"cell_type":"code","metadata":{"id":"L1uZRxt5TjGG"},"source":[""],"execution_count":null,"outputs":[]}]}