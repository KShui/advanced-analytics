{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"07_Kmeans.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"4PnvyqjpXXpE"},"source":["# 7. KMeans Clustering with Scikit-Learn and MLlib\n","\n","Implement the K-Means Algorithm using Scikit-Learn and MLlib!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ZrxrVqCXYY_","executionInfo":{"status":"ok","timestamp":1616272863355,"user_tz":-60,"elapsed":41395,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"8d2a45b5-1049-4dc4-bd6d-0547da50fdbc"},"source":["!pip install pyspark"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting pyspark\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/b0/9d6860891ab14a39d4bddf80ba26ce51c2f9dc4805e5c6978ac0472c120a/pyspark-3.1.1.tar.gz (212.3MB)\n","\u001b[K     |████████████████████████████████| 212.3MB 67kB/s \n","\u001b[?25hCollecting py4j==0.10.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n","\u001b[K     |████████████████████████████████| 204kB 18.3MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.1.1-py2.py3-none-any.whl size=212767604 sha256=f95f8d8853eb4ee2127d34ae0d99f13dcde7d3fe3069c41786da6a180058de29\n","  Stored in directory: /root/.cache/pip/wheels/0b/90/c0/01de724414ef122bd05f056541fb6a0ecf47c7ca655f8b3c0f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9 pyspark-3.1.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P2Y8NyTVXXpK","executionInfo":{"status":"ok","timestamp":1616272864570,"user_tz":-60,"elapsed":41958,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}}},"source":["%matplotlib inline\n","from sklearn import datasets\n","import pandas as pd\n","import numpy as np\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from mpl_toolkits.mplot3d import Axes3D\n","\n","from sklearn.cluster import KMeans\n","from sklearn import datasets"],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Yff3pFt5XXpL"},"source":["The dataset class provides access to different public datasets. It will return a scikit-learn bunch: <http://scikit-learn.org/stable/datasets/index.html>"]},{"cell_type":"code","metadata":{"id":"wcuwQ58SXXpM","executionInfo":{"status":"ok","timestamp":1616272864573,"user_tz":-60,"elapsed":41111,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}}},"source":["iris = datasets.load_iris()"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HV_npw8qXXpM"},"source":["Convert Scikit Bunch to Pandas Dataframe"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":204},"id":"Je0vRfgwXXpM","executionInfo":{"status":"ok","timestamp":1616272864574,"user_tz":-60,"elapsed":40337,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"04b970b5-d601-4d7c-bae8-e0dd3f9be000"},"source":["iris_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n","iris_df['target'] = iris.target\n","iris_df[\"target_name\"]=iris['target_names'][iris_df['target']] \n","iris_df.head()"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sepal length (cm)</th>\n","      <th>sepal width (cm)</th>\n","      <th>petal length (cm)</th>\n","      <th>petal width (cm)</th>\n","      <th>target</th>\n","      <th>target_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>5.1</td>\n","      <td>3.5</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>4.9</td>\n","      <td>3.0</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>4.7</td>\n","      <td>3.2</td>\n","      <td>1.3</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4.6</td>\n","      <td>3.1</td>\n","      <td>1.5</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>setosa</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5.0</td>\n","      <td>3.6</td>\n","      <td>1.4</td>\n","      <td>0.2</td>\n","      <td>0</td>\n","      <td>setosa</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   sepal length (cm)  sepal width (cm)  ...  target  target_name\n","0                5.1               3.5  ...       0       setosa\n","1                4.9               3.0  ...       0       setosa\n","2                4.7               3.2  ...       0       setosa\n","3                4.6               3.1  ...       0       setosa\n","4                5.0               3.6  ...       0       setosa\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"UREbnPtpXXpN"},"source":["## 7.1 Cluster the data using the KMeans implementation of scikit-learn!\n","\n","* Resource: <http://scikit-learn.org/stable/auto_examples/cluster/plot_cluster_iris.html>\n","* Measure the runtime for training the model!\n","* Experiment with different number of clusters! What are your observations!\n","* Plot the results!"]},{"cell_type":"markdown","metadata":{"id":"3F5_qbyZXXpO"},"source":["## 7.2 MLlib Clustering\n","\n","* MLLib KMeans Example: \n","    * <https://spark.apache.org/docs/latest/ml-clustering.html>\n","    * <https://spark.apache.org/docs/latest/api/python/>\n","    * <https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.ClusteringEvaluator>\n","* Run KMeans on the provided Iris dataset!\n","* Validate the quality of the model using the sum of the squared error for each point! Use the ClusterEvaluator of Spark MLlib!"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l4aN0_JOXXpO","executionInfo":{"status":"ok","timestamp":1616272872385,"user_tz":-60,"elapsed":46901,"user":{"displayName":"Andre Luckow","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgX3nHdZvRUbdHrLYLXgFiGSepV9F6Hd9-YYk29L-Y=s64","userId":"13897213013486729084"}},"outputId":"d7f0f18a-cd6e-4939-e52e-a57814961dfa"},"source":["# Initialize PySpark\n","import os, sys\n","APP_NAME = \"PySpark Lecture\"\n","SPARK_MASTER=\"local[1]\"\n","import pyspark\n","import pyspark.sql\n","from pyspark.sql import Row\n","conf=pyspark.SparkConf()\n","conf=pyspark.SparkConf().setAppName(APP_NAME).set(\"spark.local.dir\", os.path.join(os.getcwd(), \"tmp\"))\n","sc = pyspark.SparkContext(master=SPARK_MASTER, conf=conf)\n","spark = pyspark.sql.SparkSession(sc).builder.appName(APP_NAME).getOrCreate()\n","\n","print(\"PySpark initiated...\")"],"execution_count":7,"outputs":[{"output_type":"stream","text":["PySpark initiated...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4tFKTUZIXXpP"},"source":["#### Model Evaluation\n","\n","* https://spark.apache.org/docs/latest/api/python/pyspark.ml.html#pyspark.ml.evaluation.ClusteringEvaluator\n","\n","* Evaluator for Clustering results, which expects two input columns: prediction and features. The metric computes the Silhouette measure using the squared Euclidean distance."]},{"cell_type":"markdown","metadata":{"id":"aaNzfp22XXpP"},"source":["## 7.3 Manual KMeans Clustering\n","\n","Implement a KMeans Model using Spark MapReduce (Do Not use MLlib version!)!"]}]}